{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c912c8f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T01:59:59.754589Z",
     "iopub.status.busy": "2024-12-21T01:59:59.754291Z",
     "iopub.status.idle": "2024-12-21T01:59:59.760135Z",
     "shell.execute_reply": "2024-12-21T01:59:59.759549Z"
    },
    "papermill": {
     "duration": 0.011514,
     "end_time": "2024-12-21T01:59:59.761266",
     "exception": false,
     "start_time": "2024-12-21T01:59:59.749752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.base import clone\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import os\n",
    "# from scipy.optimize import minimize\n",
    "# from colorama import Fore, Style\n",
    "\n",
    "# # Load data\n",
    "# train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "# test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "# sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "# # Function to process time series data\n",
    "# def process_file(filename, dirname):\n",
    "#     df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "#     df.drop('step', axis=1, inplace=True)\n",
    "#     return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "# def load_time_series(dirname) -> pd.DataFrame:\n",
    "#     ids = os.listdir(dirname)\n",
    "    \n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "#     stats, indexes = zip(*results)\n",
    "    \n",
    "#     df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "#     df['id'] = indexes\n",
    "#     return df\n",
    "        \n",
    "# train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "# test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "# time_series_cols = train_ts.columns.tolist()\n",
    "# time_series_cols.remove(\"id\")\n",
    "\n",
    "# train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "# test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "# train = train.drop('id', axis=1)\n",
    "# test = test.drop('id', axis=1)   \n",
    "\n",
    "# # Feature columns\n",
    "# featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "#                 'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "#                 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "#                 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "#                 'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "#                 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "#                 'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "#                 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "#                 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "#                 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "#                 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "#                 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "#                 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "#                 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "#                 'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "#                 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "#                 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "#                 'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "# featuresCols += time_series_cols\n",
    "\n",
    "# train = train[featuresCols]\n",
    "# train = train.dropna(subset='sii')\n",
    "\n",
    "# cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "#           'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "#           'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "# def update(df):\n",
    "#     global cat_c\n",
    "#     for c in cat_c: \n",
    "#         df[c] = df[c].fillna('Missing')\n",
    "#         df[c] = df[c].astype('category')\n",
    "#     return df\n",
    "        \n",
    "# train = update(train)\n",
    "# test = update(test)\n",
    "\n",
    "# def create_mapping(column, dataset):\n",
    "#     unique_values = dataset[column].unique()\n",
    "#     return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "# for col in cat_c:\n",
    "#     mapping = create_mapping(col, train)\n",
    "#     mappingTe = create_mapping(col, test)\n",
    "    \n",
    "#     train[col] = train[col].replace(mapping).astype(int)\n",
    "#     test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "# def quadratic_weighted_kappa(y_true, y_pred):\n",
    "#     return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "# def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "#     return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "#                     np.where(oof_non_rounded < thresholds[1], 1,\n",
    "#                              np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "# def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "#     rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "#     return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "# def TrainML(model_class, test_data):\n",
    "#     X = train.drop(['sii'], axis=1)\n",
    "#     y = train['sii']\n",
    "\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "#     train_S = []\n",
    "#     test_S = []\n",
    "    \n",
    "#     oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "#     oof_rounded = np.zeros(len(y), dtype=int) \n",
    "#     test_preds = np.zeros((len(test_data), 5))\n",
    "\n",
    "#     for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=5)):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "#         model = clone(model_class)\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         y_train_pred = model.predict(X_train)\n",
    "#         y_val_pred = model.predict(X_val)\n",
    "\n",
    "#         oof_non_rounded[test_idx] = y_val_pred\n",
    "#         y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "#         oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "#         train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "#         val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "#         train_S.append(train_kappa)\n",
    "#         test_S.append(val_kappa)\n",
    "        \n",
    "#         test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "#         print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "    \n",
    "#     print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "#     print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "#     KappaOPtimizer = minimize(evaluate_predictions,\n",
    "#                               x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "#                               method='Nelder-Mead')\n",
    "#     assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "#     oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "#     tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "#     print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "    \n",
    "#     tpm = test_preds.mean(axis=1)\n",
    "#     tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "\n",
    "#     # Create final submission prediction\n",
    "#     submission = pd.DataFrame({\n",
    "#         'id': sample['id'],\n",
    "#         'sii': test_preds.mean(axis=1).round(0).astype(int)\n",
    "#     })\n",
    "\n",
    "#     return submission\n",
    "\n",
    "# # XGBoost parameters\n",
    "# Params = {\n",
    "#     'learning_rate': 0.05,\n",
    "#     'max_depth': 6,\n",
    "#     'n_estimators': 200,\n",
    "#     'subsample': 0.8,\n",
    "#     'colsample_bytree': 0.8,\n",
    "#     'reg_alpha': 1,  # Increased from 0.1\n",
    "#     'reg_lambda': 5,  # Increased from 1\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "\n",
    "# # Instantiate the XGBoost model\n",
    "# XGBoost = xgb.XGBRegressor(**Params, verbosity=0)\n",
    "\n",
    "# # Train the model and get predictions\n",
    "# Submission = TrainML(XGBoost, test)\n",
    "\n",
    "# # Output submission\n",
    "# Submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbebee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T01:59:59.767731Z",
     "iopub.status.busy": "2024-12-21T01:59:59.767523Z",
     "iopub.status.idle": "2024-12-21T01:59:59.772026Z",
     "shell.execute_reply": "2024-12-21T01:59:59.771414Z"
    },
    "papermill": {
     "duration": 0.008878,
     "end_time": "2024-12-21T01:59:59.773177",
     "exception": false,
     "start_time": "2024-12-21T01:59:59.764299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.base import clone\n",
    "# from scipy.optimize import minimize\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import os\n",
    "# from colorama import Fore, Style\n",
    "\n",
    "# # Load data\n",
    "# train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "# test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "# sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "# # Function to process time series data\n",
    "# def process_file(filename, dirname):\n",
    "#     df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "#     df.drop('step', axis=1, inplace=True)\n",
    "#     return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "# def load_time_series(dirname) -> pd.DataFrame:\n",
    "#     ids = os.listdir(dirname)\n",
    "    \n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "#     stats, indexes = zip(*results)\n",
    "    \n",
    "#     df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "#     df['id'] = indexes\n",
    "#     return df\n",
    "        \n",
    "# train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "# test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "# time_series_cols = train_ts.columns.tolist()\n",
    "# time_series_cols.remove(\"id\")\n",
    "\n",
    "# train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "# test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "# train = train.drop('id', axis=1)\n",
    "# test = test.drop('id', axis=1)   \n",
    "\n",
    "# # Feature columns\n",
    "# featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "#                 'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "#                 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "#                 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "#                 'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "#                 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "#                 'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "#                 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "#                 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "#                 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "#                 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "#                 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "#                 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "#                 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "#                 'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "#                 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "#                 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "#                 'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "# featuresCols += time_series_cols\n",
    "\n",
    "# train = train[featuresCols]\n",
    "# train = train.dropna(subset='sii')\n",
    "\n",
    "# cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "#           'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "#           'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "# def update(df):\n",
    "#     global cat_c\n",
    "#     for c in cat_c: \n",
    "#         df[c] = df[c].fillna('Missing')\n",
    "#         df[c] = df[c].astype('category')\n",
    "#     return df\n",
    "        \n",
    "# train = update(train)\n",
    "# test = update(test)\n",
    "\n",
    "# def create_mapping(column, dataset):\n",
    "#     unique_values = dataset[column].unique()\n",
    "#     return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "# for col in cat_c:\n",
    "#     mapping = create_mapping(col, train)\n",
    "#     mappingTe = create_mapping(col, test)\n",
    "    \n",
    "#     train[col] = train[col].replace(mapping).astype(int)\n",
    "#     test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "# def quadratic_weighted_kappa(y_true, y_pred):\n",
    "#     return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "# def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "#     return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "#                     np.where(oof_non_rounded < thresholds[1], 1,\n",
    "#                              np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "# def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "#     rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "#     return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "# def TrainML(model_class, test_data):\n",
    "#     X = train.drop(['sii'], axis=1)\n",
    "#     y = train['sii']\n",
    "\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "#     train_S = []\n",
    "#     test_S = []\n",
    "    \n",
    "#     oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "#     oof_rounded = np.zeros(len(y), dtype=int) \n",
    "#     test_preds = np.zeros((len(test_data), 5))\n",
    "\n",
    "#     for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=5)):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "#         model = clone(model_class)\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         y_train_pred = model.predict(X_train)\n",
    "#         y_val_pred = model.predict(X_val)\n",
    "\n",
    "#         oof_non_rounded[test_idx] = y_val_pred\n",
    "#         y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "#         oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "#         train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "#         val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "#         train_S.append(train_kappa)\n",
    "#         test_S.append(val_kappa)\n",
    "        \n",
    "#         test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "#         print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "    \n",
    "#     print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "#     print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "#     KappaOPtimizer = minimize(evaluate_predictions,\n",
    "#                               x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "#                               method='Nelder-Mead')\n",
    "#     assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "#     oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "#     tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "#     print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "    \n",
    "#     tpm = test_preds.mean(axis=1)\n",
    "#     tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "\n",
    "#     # Create final submission prediction\n",
    "#     submission = pd.DataFrame({\n",
    "#         'id': sample['id'],\n",
    "#         'sii': test_preds.mean(axis=1).round(0).astype(int)\n",
    "#     })\n",
    "\n",
    "#     return submission\n",
    "\n",
    "# # CatBoost parameters\n",
    "# CatBoost_Params = {\n",
    "#     'learning_rate': 0.05,\n",
    "#     'depth': 6,\n",
    "#     'iterations': 200,\n",
    "#     'random_seed': 42,\n",
    "#     'verbose': 0,\n",
    "#     'l2_leaf_reg': 10, \n",
    "#     'task_type': 'GPU'\n",
    "# }\n",
    "\n",
    "# # Instantiate the CatBoost model\n",
    "# CatBoost_Model = CatBoostRegressor(**CatBoost_Params)\n",
    "\n",
    "# # Train the model and get predictions\n",
    "# Submission = TrainML(CatBoost_Model, test)\n",
    "\n",
    "# # Output submission\n",
    "# Submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a83125",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-21T01:59:59.779145Z",
     "iopub.status.busy": "2024-12-21T01:59:59.778950Z",
     "iopub.status.idle": "2024-12-21T01:59:59.783578Z",
     "shell.execute_reply": "2024-12-21T01:59:59.782809Z"
    },
    "papermill": {
     "duration": 0.009079,
     "end_time": "2024-12-21T01:59:59.784846",
     "exception": false,
     "start_time": "2024-12-21T01:59:59.775767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.base import clone\n",
    "# from scipy.optimize import minimize\n",
    "# import os\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from scipy.optimize import minimize\n",
    "# from colorama import Fore, Style\n",
    "\n",
    "# # Load data\n",
    "# train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "# test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "# sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "# # Function to process time series data\n",
    "# def process_file(filename, dirname):\n",
    "#     df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "#     df.drop('step', axis=1, inplace=True)\n",
    "#     return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "# def load_time_series(dirname) -> pd.DataFrame:\n",
    "#     ids = os.listdir(dirname)\n",
    "    \n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "#     stats, indexes = zip(*results)\n",
    "    \n",
    "#     df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "#     df['id'] = indexes\n",
    "#     return df\n",
    "        \n",
    "# train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "# test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "# time_series_cols = train_ts.columns.tolist()\n",
    "# time_series_cols.remove(\"id\")\n",
    "\n",
    "# train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "# test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "# train = train.drop('id', axis=1)\n",
    "# test = test.drop('id', axis=1)   \n",
    "\n",
    "# # Feature columns\n",
    "# featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "#                 'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "#                 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "#                 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "#                 'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "#                 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "#                 'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "#                 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "#                 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "#                 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "#                 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "#                 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "#                 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "#                 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "#                 'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "#                 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "#                 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "#                 'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "# featuresCols += time_series_cols\n",
    "\n",
    "# train = train[featuresCols]\n",
    "# train = train.dropna(subset='sii')\n",
    "\n",
    "# cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "#           'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "#           'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "# def update(df):\n",
    "#     global cat_c\n",
    "#     for c in cat_c: \n",
    "#         df[c] = df[c].fillna('Missing')\n",
    "#         df[c] = df[c].astype('category')\n",
    "#     return df\n",
    "        \n",
    "# train = update(train)\n",
    "# test = update(test)\n",
    "\n",
    "# def create_mapping(column, dataset):\n",
    "#     unique_values = dataset[column].unique()\n",
    "#     return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "# for col in cat_c:\n",
    "#     mapping = create_mapping(col, train)\n",
    "#     mappingTe = create_mapping(col, test)\n",
    "    \n",
    "#     train[col] = train[col].replace(mapping).astype(int)\n",
    "#     test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "# def quadratic_weighted_kappa(y_true, y_pred):\n",
    "#     return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "# def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "#     return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "#                     np.where(oof_non_rounded < thresholds[1], 1,\n",
    "#                              np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "# def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "#     rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "#     return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "# def TrainML(model_class, test_data):\n",
    "#     X = train.drop(['sii'], axis=1)\n",
    "#     y = train['sii']\n",
    "\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "#     train_S = []\n",
    "#     test_S = []\n",
    "    \n",
    "#     oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "#     oof_rounded = np.zeros(len(y), dtype=int) \n",
    "#     test_preds = np.zeros((len(test_data), 5))\n",
    "\n",
    "#     for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=5)):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "#         model = clone(model_class)\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         y_train_pred = model.predict(X_train)\n",
    "#         y_val_pred = model.predict(X_val)\n",
    "\n",
    "#         oof_non_rounded[test_idx] = y_val_pred\n",
    "#         y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "#         oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "#         train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "#         val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "#         train_S.append(train_kappa)\n",
    "#         test_S.append(val_kappa)\n",
    "        \n",
    "#         test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "#         print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "    \n",
    "#     print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "#     print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "#         # After the for loop ends (Line 149, after the last fold is processed)\n",
    "#     KappaOPtimizer = minimize(evaluate_predictions,\n",
    "#                               x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "#                               method='Nelder-Mead')\n",
    "#     assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "#     oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "#     tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "#     print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "    \n",
    "#     tpm = test_preds.mean(axis=1)\n",
    "#     tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "\n",
    "#     # Create final submission prediction\n",
    "#     submission = pd.DataFrame({\n",
    "#         'id': sample['id'],\n",
    "#         'sii': test_preds.mean(axis=1).round(0).astype(int)\n",
    "#     })\n",
    "\n",
    "#     return submission\n",
    "\n",
    "\n",
    "# # LGBM model parameters\n",
    "# Params = {\n",
    "#     'learning_rate': 0.046,\n",
    "#     'max_depth': 12,\n",
    "#     'num_leaves': 478,\n",
    "#     'min_data_in_leaf': 13,\n",
    "#     'feature_fraction': 0.893,\n",
    "#     'bagging_fraction': 0.784,\n",
    "#     'bagging_freq': 4,\n",
    "#     'lambda_l1': 10,  # Increased from 6.59\n",
    "#     'lambda_l2': 0.01  # Increased from 2.68e-06\n",
    "# }\n",
    "\n",
    "# # Instantiate the LGBMRegressor model\n",
    "# Light = LGBMRegressor(**Params, random_state=42, verbose=-1, n_estimators=300)\n",
    "\n",
    "# # Train the model and get predictions\n",
    "# Submission = TrainML(Light, test)\n",
    "\n",
    "# # Output submission\n",
    "# Submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37eeb07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T01:59:59.791829Z",
     "iopub.status.busy": "2024-12-21T01:59:59.791593Z",
     "iopub.status.idle": "2024-12-21T01:59:59.796432Z",
     "shell.execute_reply": "2024-12-21T01:59:59.795696Z"
    },
    "papermill": {
     "duration": 0.009701,
     "end_time": "2024-12-21T01:59:59.797567",
     "exception": false,
     "start_time": "2024-12-21T01:59:59.787866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.base import clone\n",
    "# from scipy.optimize import minimize\n",
    "# import os\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from colorama import Fore, Style\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.impute import KNNImputer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# # Load data\n",
    "# train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "# test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "# sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "# # Function to process time series data\n",
    "# def process_file(filename, dirname):\n",
    "#     df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "#     df.drop('step', axis=1, inplace=True)\n",
    "#     return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "# def load_time_series(dirname) -> pd.DataFrame:\n",
    "#     ids = os.listdir(dirname)\n",
    "    \n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "#     stats, indexes = zip(*results)\n",
    "    \n",
    "#     df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "#     df['id'] = indexes\n",
    "#     return df\n",
    "        \n",
    "# train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "# test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "# time_series_cols = train_ts.columns.tolist()\n",
    "# time_series_cols.remove(\"id\")\n",
    "\n",
    "# train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "# test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "# train = train.drop('id', axis=1)\n",
    "# test = test.drop('id', axis=1)   \n",
    "\n",
    "# # Feature columns\n",
    "# featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "#                 'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "#                 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "#                 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "#                 'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "#                 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "#                 'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "#                 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "#                 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "#                 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "#                 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "#                 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "#                 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "#                 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "#                 'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "#                 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "#                 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "#                 'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "# featuresCols += time_series_cols\n",
    "\n",
    "# train = train[featuresCols]\n",
    "# train = train.dropna(subset='sii')\n",
    "\n",
    "# cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "#           'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "#           'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "# def update(df):\n",
    "#     global cat_c\n",
    "#     for c in cat_c: \n",
    "#         df[c] = df[c].fillna('Missing')\n",
    "#         df[c] = df[c].astype('category')\n",
    "#     return df\n",
    "        \n",
    "# train = update(train)\n",
    "# test = update(test)\n",
    "\n",
    "# def create_mapping(column, dataset):\n",
    "#     unique_values = dataset[column].unique()\n",
    "#     return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "# for col in cat_c:\n",
    "#     mapping = create_mapping(col, train)\n",
    "#     mappingTe = create_mapping(col, test)\n",
    "    \n",
    "#     train[col] = train[col].replace(mapping).astype(int)\n",
    "#     test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "# def quadratic_weighted_kappa(y_true, y_pred):\n",
    "#     return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "# def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "#     return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "#                     np.where(oof_non_rounded < thresholds[1], 1,\n",
    "#                              np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "# def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "#     rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "#     return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "\n",
    "# def create_pipeline(model_class):\n",
    "#     return Pipeline([\n",
    "#         ('imputer', KNNImputer(n_neighbors=5)),\n",
    "#         ('model', model_class)\n",
    "#     ])\n",
    "\n",
    "# def TrainML(model_class, test_data):\n",
    "#     X = train.drop(['sii'], axis=1)\n",
    "#     y = train['sii']\n",
    "\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "#     train_S = []\n",
    "#     test_S = []\n",
    "    \n",
    "#     oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "#     oof_rounded = np.zeros(len(y), dtype=int) \n",
    "#     test_preds = np.zeros((len(test_data), 5))\n",
    "\n",
    "#     for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=5)):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "#         # Create a new pipeline for each fold\n",
    "#         pipeline = create_pipeline(clone(model_class))\n",
    "#         pipeline.fit(X_train, y_train)\n",
    "\n",
    "#         y_train_pred = pipeline.predict(X_train)\n",
    "#         y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "#         oof_non_rounded[test_idx] = y_val_pred\n",
    "#         y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "#         oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "#         train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "#         val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "#         train_S.append(train_kappa)\n",
    "#         test_S.append(val_kappa)\n",
    "        \n",
    "#         test_preds[:, fold] = pipeline.predict(test_data)\n",
    "        \n",
    "#         print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "    \n",
    "#     print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "#     print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "#     KappaOptimizer = minimize(evaluate_predictions,\n",
    "#                             x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "#                             method='Nelder-Mead')\n",
    "#     assert KappaOptimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "#     oof_tuned = threshold_Rounder(oof_non_rounded, KappaOptimizer.x)\n",
    "#     tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "#     print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "    \n",
    "#     tpm = test_preds.mean(axis=1)\n",
    "#     tpTuned = threshold_Rounder(tpm, KappaOptimizer.x)\n",
    "\n",
    "#     # Create final submission prediction\n",
    "#     submission = pd.DataFrame({\n",
    "#         'id': sample['id'],\n",
    "#         'sii': tpTuned  # Use the tuned predictions instead of rounded means\n",
    "#     })\n",
    "\n",
    "#     return submission\n",
    "\n",
    "# # Random Forest parameters\n",
    "# RF_Params = {\n",
    "#     'n_estimators': 100,\n",
    "#     'max_depth': 12,\n",
    "#     'min_samples_split': 5,\n",
    "#     'min_samples_leaf': 2,\n",
    "#     'random_state': 42\n",
    "# }\n",
    "\n",
    "# # Instantiate the RandomForestRegressor model\n",
    "# RF = RandomForestRegressor(**RF_Params)\n",
    "\n",
    "# # Train the model and get predictions\n",
    "# Submission = TrainML(RF, test)\n",
    "\n",
    "# # Output submission\n",
    "# Submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0095f40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T01:59:59.803601Z",
     "iopub.status.busy": "2024-12-21T01:59:59.803387Z",
     "iopub.status.idle": "2024-12-21T01:59:59.807966Z",
     "shell.execute_reply": "2024-12-21T01:59:59.807227Z"
    },
    "papermill": {
     "duration": 0.00894,
     "end_time": "2024-12-21T01:59:59.809114",
     "exception": false,
     "start_time": "2024-12-21T01:59:59.800174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import cohen_kappa_score\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.base import clone\n",
    "# from scipy.optimize import minimize\n",
    "# import os\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from colorama import Fore, Style\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.impute import KNNImputer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# # Load data\n",
    "# train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "# test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "# sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "# # Function to process time series data\n",
    "# def process_file(filename, dirname):\n",
    "#     df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "#     df.drop('step', axis=1, inplace=True)\n",
    "#     return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "# def load_time_series(dirname) -> pd.DataFrame:\n",
    "#     ids = os.listdir(dirname)\n",
    "    \n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "#     stats, indexes = zip(*results)\n",
    "    \n",
    "#     df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "#     df['id'] = indexes\n",
    "#     return df\n",
    "        \n",
    "# train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "# test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "# time_series_cols = train_ts.columns.tolist()\n",
    "# time_series_cols.remove(\"id\")\n",
    "\n",
    "# train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "# test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "# train = train.drop('id', axis=1)\n",
    "# test = test.drop('id', axis=1)   \n",
    "\n",
    "# # Feature columns\n",
    "# featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "#                 'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "#                 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "#                 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "#                 'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "#                 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "#                 'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "#                 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "#                 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "#                 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "#                 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "#                 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "#                 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "#                 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "#                 'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "#                 'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "#                 'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "#                 'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "# featuresCols += time_series_cols\n",
    "\n",
    "# train = train[featuresCols]\n",
    "# train = train.dropna(subset='sii')\n",
    "\n",
    "# cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "#           'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "#           'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "# def update(df):\n",
    "#     global cat_c\n",
    "#     for c in cat_c: \n",
    "#         df[c] = df[c].fillna('Missing')\n",
    "#         df[c] = df[c].astype('category')\n",
    "#     return df\n",
    "        \n",
    "# train = update(train)\n",
    "# test = update(test)\n",
    "\n",
    "# def create_mapping(column, dataset):\n",
    "#     unique_values = dataset[column].unique()\n",
    "#     return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "# for col in cat_c:\n",
    "#     mapping = create_mapping(col, train)\n",
    "#     mappingTe = create_mapping(col, test)\n",
    "    \n",
    "#     train[col] = train[col].replace(mapping).astype(int)\n",
    "#     test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "# def quadratic_weighted_kappa(y_true, y_pred):\n",
    "#     return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "# def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "#     return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "#                     np.where(oof_non_rounded < thresholds[1], 1,\n",
    "#                              np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "# def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "#     rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "#     return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "\n",
    "# def create_pipeline(model_class):\n",
    "#     return Pipeline([\n",
    "#         ('imputer', KNNImputer(n_neighbors=5)),\n",
    "#         ('model', model_class)\n",
    "#     ])\n",
    "\n",
    "# def TrainML(model_class, test_data):\n",
    "#     X = train.drop(['sii'], axis=1)\n",
    "#     y = train['sii']\n",
    "\n",
    "#     SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "#     train_S = []\n",
    "#     test_S = []\n",
    "    \n",
    "#     oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "#     oof_rounded = np.zeros(len(y), dtype=int) \n",
    "#     test_preds = np.zeros((len(test_data), 5))\n",
    "\n",
    "#     for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=5)):\n",
    "#         X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "#         # Create a new pipeline for each fold\n",
    "#         pipeline = create_pipeline(clone(model_class))\n",
    "#         pipeline.fit(X_train, y_train)\n",
    "\n",
    "#         y_train_pred = pipeline.predict(X_train)\n",
    "#         y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "#         oof_non_rounded[test_idx] = y_val_pred\n",
    "#         y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "#         oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "#         train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "#         val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "#         train_S.append(train_kappa)\n",
    "#         test_S.append(val_kappa)\n",
    "        \n",
    "#         test_preds[:, fold] = pipeline.predict(test_data)\n",
    "        \n",
    "#         print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "    \n",
    "#     print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "#     print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "#     KappaOptimizer = minimize(evaluate_predictions,\n",
    "#                             x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "#                             method='Nelder-Mead')\n",
    "#     assert KappaOptimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "#     oof_tuned = threshold_Rounder(oof_non_rounded, KappaOptimizer.x)\n",
    "#     tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "#     print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "    \n",
    "#     tpm = test_preds.mean(axis=1)\n",
    "#     tpTuned = threshold_Rounder(tpm, KappaOptimizer.x)\n",
    "\n",
    "#     # Create final submission prediction\n",
    "#     submission = pd.DataFrame({\n",
    "#         'id': sample['id'],\n",
    "#         'sii': tpTuned  # Use the tuned predictions instead of rounded means\n",
    "#     })\n",
    "\n",
    "#     return submission\n",
    "\n",
    "# GB_Params = {\n",
    "#     \"n_estimators\": 295,\n",
    "#     \"learning_rate\": 0.012,\n",
    "#     \"max_depth\": 3,\n",
    "#     \"min_samples_split\": 18,\n",
    "#     \"min_samples_leaf\": 5,\n",
    "#     \"subsample\": 0.6,\n",
    "#     \"max_features\": None,\n",
    "#     \"random_state\": 42,\n",
    "# }\n",
    "\n",
    "# # Instantiate the RandomForestRegressor model\n",
    "# GB = GradientBoostingRegressor(**GB_Params)\n",
    "\n",
    "# # Train the model and get predictions\n",
    "# Submission = TrainML(GB, test)\n",
    "\n",
    "# # Output submission\n",
    "# Submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb96da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T01:59:59.815045Z",
     "iopub.status.busy": "2024-12-21T01:59:59.814803Z",
     "iopub.status.idle": "2024-12-21T02:01:50.048408Z",
     "shell.execute_reply": "2024-12-21T02:01:50.047455Z"
    },
    "papermill": {
     "duration": 110.238425,
     "end_time": "2024-12-21T02:01:50.050054",
     "exception": false,
     "start_time": "2024-12-21T01:59:59.811629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:10<00:00, 14.12it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.20it/s]\n",
      "Training Folds:  20%|██        | 1/5 [00:07<00:28,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train QWK: 0.4467, Validation QWK: 0.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds:  40%|████      | 2/5 [00:14<00:21,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Train QWK: 0.4168, Validation QWK: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds:  60%|██████    | 3/5 [00:21<00:14,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Train QWK: 0.4722, Validation QWK: 0.3068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds:  80%|████████  | 4/5 [00:29<00:07,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - Train QWK: 0.4810, Validation QWK: 0.2992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:37<00:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - Train QWK: 0.4763, Validation QWK: 0.2287\n",
      "Mean Train QWK --> 0.4586\n",
      "Mean Validation QWK ---> 0.3013\n",
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.308\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor# from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import clone\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from colorama import Fore, Style\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "# Function to process time series data\n",
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "        \n",
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)   \n",
    "\n",
    "# Feature columns\n",
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping = create_mapping(col, train)\n",
    "    mappingTe = create_mapping(col, test)\n",
    "    \n",
    "    train[col] = train[col].replace(mapping).astype(int)\n",
    "    test[col] = test[col].replace(mappingTe).astype(int)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "def create_pipeline(model_class):\n",
    "    return Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('model', model_class)\n",
    "    ])\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), 5))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=5)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Create a new pipeline for each fold\n",
    "        pipeline = create_pipeline(clone(model_class))\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = pipeline.predict(X_train)\n",
    "        y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = pipeline.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "    \n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOptimizer = minimize(evaluate_predictions,\n",
    "                            x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                            method='Nelder-Mead')\n",
    "    assert KappaOptimizer.success, \"Optimization did not converge.\"\n",
    "\n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOptimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "    \n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOptimizer.x)\n",
    "\n",
    "    # Create final submission prediction\n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned  # Use the tuned predictions instead of rounded means\n",
    "    })\n",
    "\n",
    "    return submission\n",
    "\n",
    "DT_Params = {\n",
    "    \"max_depth\": 5,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# Instantiate the DecisionTreeRegressor model\n",
    "DT = DecisionTreeRegressor(**DT_Params)\n",
    "\n",
    "# Train the model and get predictions\n",
    "Submission = TrainML(DT, test)\n",
    "\n",
    "# Output submission\n",
    "Submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 113.02359,
   "end_time": "2024-12-21T02:01:50.587405",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-21T01:59:57.563815",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
